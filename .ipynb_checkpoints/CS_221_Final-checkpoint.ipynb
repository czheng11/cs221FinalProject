{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xcbsnDYk3AV9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Packages to import\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.layers import Dense\n",
    "from keras.regularizers import l1, l2\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.pyplot import figure\n",
    "import pandas as pd\n",
    "import operator\n",
    "from math import log\n",
    "from pandas import Series, DataFrame\n",
    "from pylab import rcParams\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import KFold # import KFold\n",
    "from sklearn import datasets\n",
    "\n",
    "#Models\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D #<-- Note the capitalization! \n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Icy10EFN3IXB"
   },
   "outputs": [],
   "source": [
    "def loadData(who):\n",
    "    all_filenames = ['2014_clean1.csv', '2016_clean1.csv', '2017_clean1.csv', '2018_clean1.csv']\n",
    "    #combine all files in the list\n",
    "    combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames])\n",
    "    #export to csv\n",
    "    combined_csv.to_csv(\"combined.csv\", index=False, encoding='utf-8-sig')\n",
    "    train=pd.read_csv('2018_clean1.csv')\n",
    "    combined=pd.read_csv('combined.csv')\n",
    "    colName = 'discuss_mental_'+who+'_Maybe'\n",
    "    if colName in combined:\n",
    "        combined = combined[combined[colName] == 0]\n",
    "    else: print('malformed')\n",
    "    return train, combined\n",
    "\n",
    "def performLogReg(X,y, test_sz = 0.2, random_state = 42):\n",
    "  # split X and y into training and testing sets\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_sz, random_state=random_state)\n",
    "\n",
    "  # instantiate the model (using the default parameters)\n",
    "  logreg = LogisticRegression()\n",
    "\n",
    "  # fit the model with data\n",
    "  logreg.fit(X_train,y_train)\n",
    "\n",
    "  # predict\n",
    "  y_pred=logreg.predict(X_test)\n",
    "\n",
    "  print(classification_report(y_test,y_pred))\n",
    "\n",
    "  cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "  print(\"Confusion matrix: \\n\" + str(cnf_matrix))\n",
    "  print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "  print(\"Precision:\", metrics.precision_score(y_test, y_pred))\n",
    "  print(\"Recall:\", metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "  y_pred_proba = logreg.predict_proba(X_test)[::,1]\n",
    "  fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)\n",
    "  auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "  plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "  plt.legend(loc=4)\n",
    "  plt.title(y.columns[0])\n",
    "  plt.close()\n",
    "  return logreg\n",
    "\n",
    "def printAndShowCoef(feature_cols, model):\n",
    "  weights_dict = {}\n",
    "  for i, feature in enumerate(feature_cols):\n",
    "    weights_dict[feature] = model.coef_[0][i]\n",
    "  weights_dict = sorted(weights_dict.items(), key=operator.itemgetter(1))\n",
    "  \n",
    "  top_10 = weights_dict[-10:]\n",
    "  top_10.reverse()\n",
    "  zip(*top_10)\n",
    "  plt.figure(figsize=(15,5))\n",
    "  plt.scatter(*zip(*top_10))\n",
    "  plt.title(y.columns[0] + \" top positive features\")\n",
    "  plt.savefig(y.columns[0] + ' top_pos6.png')\n",
    "  plt.close()\n",
    "\n",
    "  low_10 = weights_dict[:10]\n",
    "  zip(*low_10)\n",
    "  plt.figure(figsize=(15,5))\n",
    "  plt.scatter(*zip(*low_10))\n",
    "  plt.title(y.columns[0] + \" top negative features\")\n",
    "  plt.savefig(y.columns[0] + ' neg_6.png')\n",
    "  return weights_dict\n",
    "\n",
    "def buildData(dataset, who, train):\n",
    "  #split dataset in features and target variable\n",
    "  # feature_cols = ['country', 'state', 'self_employed', 'family_history', 'treatment', 'interfere', 'size', 'tech',\t'benefits',\t'options', 'wellness_program',\t'resources', 'anon', 'leave', 'interview_mental_health', 'interview_physical_health', 'observe_negative']\n",
    "  root = 'discuss_mental_'+who \n",
    "  target_col = root+'_Yes'\n",
    "  ignoreAdd = [root+'_Maybe', root+'_No', target_col, root+'_Some of them']\n",
    "  if who != 'supervisor':\n",
    "        ignoreAdd.extend(['Unnamed: 0', root+'nan'])\n",
    "  feature_cols = list(train.columns)\n",
    "  remove_list = ['age', 'country', 'state', 'work_remotely','mental_health_seriously', 'employer_negative_consequence_mental', 'employer_negative_consequence_physical']\n",
    "  remove_list.extend(ignoreAdd)\n",
    "  for delete_info in remove_list:\n",
    "    if delete_info in train.columns:\n",
    "      feature_cols.remove(delete_info)\n",
    "  X = dataset[feature_cols] # Features\n",
    "  for feature in feature_cols:\n",
    "    X.loc[X[feature] != 1, feature] = 0\n",
    "  y = dataset[[target_col]] # Target variable\n",
    "  # for feature in feature_cols:\n",
    "  y.to_csv(\"y.csv\", index=False, encoding='utf-8-sig')\n",
    "  y.loc[y[target_col] != 1, target_col] = 0\n",
    "  return X, y, feature_cols\n",
    "  return(performLogReg(X,y, feature_cols))\n",
    "\n",
    "def printListCoefs(X, logreg):\n",
    "    features = list(X.columns)\n",
    "    coefficients = {}\n",
    "    for i, f in enumerate(features):\n",
    "      coefficients[f] = logreg.coef_[0][i]\n",
    "    import operator\n",
    "    sorted_coefficients = sorted(coefficients.items(), key=operator.itemgetter(1))\n",
    "    print(sorted_coefficients[::-1])\n",
    "    print('Number of features: ', len(features))\n",
    "    print('Number of entries: ',len(X))\n",
    "\n",
    "def runDifferentModels(X,Y):\n",
    "  # split X and y into training and testing sets\n",
    "  X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X, Y, test_size=0.3)\n",
    "  X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)\n",
    "  print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)\n",
    "  # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "  #\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\"Naive Bayes\", \"QDA\"\n",
    "  models = []\n",
    "  models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "  models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "  models.append(('GP', GaussianProcessClassifier()))\n",
    "  models.append(('RF', RandomForestClassifier()))\n",
    "  models.append(('NN', MLPClassifier()))\n",
    "  models.append(('AB', AdaBoostClassifier()))\n",
    "  models.append(('QDA', QuadraticDiscriminantAnalysis()))\n",
    "  models.append(('CART', DecisionTreeClassifier()))\n",
    "  models.append(('NB', GaussianNB()))\n",
    "  models.append(('K_M', KNeighborsClassifier(metric = 'minkowski')))\n",
    "  models.append(('K_C', KNeighborsClassifier(metric = 'chebyshev')))\n",
    "  models.append(('K_E', KNeighborsClassifier(metric = 'euclidean')))\n",
    "  models.append(('K_Man', KNeighborsClassifier(metric = 'manhattan')))\n",
    "  models.append(('K_Mat', KNeighborsClassifier(metric = 'matching')))\n",
    "  models.append(('K_J', KNeighborsClassifier(metric = 'jaccard')))\n",
    "  models.append(('K_D', KNeighborsClassifier(metric = 'dice')))\n",
    "  models.append(('K_K', KNeighborsClassifier(metric = 'kulsinski')))\n",
    "  models.append(('S_Lin', SVC(kernel='linear')))\n",
    "  models.append(('S_RBF', SVC(kernel='rbf')))\n",
    "  models.append(('S_Sig', SVC(kernel=\"sigmoid\")))\n",
    "  models.append(('S_Pol', SVC(kernel=\"poly\")))\n",
    "  \n",
    "\n",
    "  # Evaluate each model through 10-fold cross-validation\n",
    "  results = []\n",
    "  names = []\n",
    "  number = 1\n",
    "  for name, model in models:\n",
    "      kfold = KFold(n_splits=10, random_state=42)\n",
    "      cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "      results.append(cv_results)\n",
    "      names.append(name)\n",
    "      msg = \"%i) %s: Mean = %f with std = (%f)\" % (number, name, cv_results.mean(), cv_results.std())\n",
    "      number += 1\n",
    "      print(msg)\n",
    "  # Compare Algorithms\n",
    "  matplotlib.rcParams.update({'font.size': 20})\n",
    "  fig = plt.figure()\n",
    "  fig = plt.figure(figsize=(14,10))\n",
    "  plt.title('Algorithm Comparison')\n",
    "  ax = fig\n",
    "  medianprops = {'color': 'magenta', 'linewidth': 3}\n",
    "  boxprops = {'color': 'black', 'linewidth': 2, 'linestyle': '-'}\n",
    "  whiskerprops = {'color': 'black', 'linewidth': 2, 'linestyle': '-'}\n",
    "  capprops = {'color': 'black', 'linewidth': 2, 'linestyle': '-'}\n",
    "  flierprops = {'color': 'black', 'marker': 'x'}\n",
    "  plt.boxplot(results,\n",
    "           medianprops=medianprops,\n",
    "           boxprops=boxprops,\n",
    "           whiskerprops=whiskerprops,\n",
    "           capprops=capprops,\n",
    "           flierprops=flierprops)\n",
    "#   ax.set_xticklabels(names)\n",
    "  plt.xlabel('Model Number', fontsize=20)\n",
    "  plt.ylabel('Accuracy', fontsize=20)\n",
    "  plt.savefig('Algorithm Comparison')\n",
    "\n",
    "def runKNN_SVMModels(X,y):\n",
    "  # split X and y into training and testing sets\n",
    "  X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X, Y, test_size=0.3)\n",
    "  X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)\n",
    "  print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)\n",
    "  #\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\"Naive Bayes\", \"QDA\"\n",
    "  models = []\n",
    "  models.append(('K_M', KNeighborsClassifier(metric = 'minkowski')))\n",
    "  models.append(('K_C', KNeighborsClassifier(metric = 'chebyshev')))\n",
    "  models.append(('K_E', KNeighborsClassifier(metric = 'euclidean')))\n",
    "  models.append(('K_Man', KNeighborsClassifier(metric = 'manhattan')))\n",
    "  models.append(('K_Mat', KNeighborsClassifier(metric = 'matching')))\n",
    "  models.append(('K_J', KNeighborsClassifier(metric = 'jaccard')))\n",
    "  models.append(('K_D', KNeighborsClassifier(metric = 'dice')))\n",
    "  models.append(('K_K', KNeighborsClassifier(metric = 'kulsinski')))\n",
    "  models.append(('S_Lin', SVC(kernel='linear')))\n",
    "  models.append(('S_RBF', SVC(kernel='rbf')))\n",
    "  models.append(('S_Sig', SVC(kernel=\"sigmoid\")))\n",
    "  models.append(('S_Pol', SVC(kernel=\"poly\")))\n",
    "  \n",
    "  # Evaluate each model through 10-fold cross-validation\n",
    "  results = []\n",
    "  names = []\n",
    "  for name, model in models:\n",
    "      kfold = KFold(n_splits=10, random_state=42)\n",
    "      cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "      results.append(cv_results)\n",
    "      names.append(name)\n",
    "      msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "      print(msg)\n",
    "  # Compare Algorithms\n",
    "  fig = plt.figure()\n",
    "  \n",
    "  fig.suptitle('Algorithm Comparison')\n",
    "  ax = fig.add_subplot(111)\n",
    "  plt.boxplot(results)\n",
    "  ax.set_xticklabels(names)\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.savefig('Comparison.png')\n",
    "\n",
    "def testPCA(X, Y):\n",
    "    pca = PCA(n_components=2)\n",
    "    principalComponents = pca.fit_transform(X)\n",
    "    principalDf = pd.DataFrame(data = principalComponents\n",
    "                 , columns = ['principal component 1', 'principal component 2'])\n",
    "    fig = plt.figure(figsize = (14,10))\n",
    "    # ax = Axes3D(fig)\n",
    "    ax = fig.add_subplot(1,1,1) \n",
    "    ax.set_xlabel('Principal Component 1', fontsize = 25)\n",
    "    ax.set_ylabel('Principal Component 2', fontsize = 25)\n",
    "    ax.set_title('2 component PCA', fontsize = 30)\n",
    "    targets = ['discuss_mental_supervisor_Yes']\n",
    "    colors = ['r']\n",
    "    for target, color in zip(targets,colors):\n",
    "        cset = ax.scatter(principalDf['principal component 1']\n",
    "                   , principalDf['principal component 2']\n",
    "                   , 16)\n",
    "    plt.savefig('PCA2.png')\n",
    "    print(principalDf.columns)\n",
    "    print(len(X.columns))\n",
    "    print(Y)\n",
    "\n",
    "    performLogReg(principalDf,Y)\n",
    "\n",
    "    pca = PCA(n_components=3)\n",
    "    principalComponents = pca.fit_transform(X)\n",
    "    principalDf = pd.DataFrame(data = principalComponents\n",
    "                 , columns = ['principal component 1', 'principal component 2', 'principal component 3'])\n",
    "    print(principalDf.columns)\n",
    "    print(len(X.columns))\n",
    "    print(Y)\n",
    "\n",
    "    performLogReg(principalDf,Y)\n",
    "\n",
    "    pca = PCA().fit(X)\n",
    "    #Plotting the Cumulative Summation of the Explained Variance\n",
    "    fig = plt.figure(figsize = (14,10))\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_), )\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('Variance (%)') #for each component\n",
    "    plt.title('Dataset Explained Variance')\n",
    "    plt.savefig('PCAVariance.png')\n",
    "\n",
    "    my_model = PCA(n_components=0.99, svd_solver='full')\n",
    "    my_model.fit_transform(X)\n",
    "    print(my_model.explained_variance_ratio_)\n",
    "    print(len(my_model.explained_variance_ratio_))\n",
    "    print(my_model.explained_variance_ratio_.cumsum())\n",
    "\n",
    "def runNeuralNet(X, Y, test_size = 0.3):\n",
    "    # X_train (10 input features, 70% of full dataset), X_val (10 input features, 15% of full dataset), X_test (10 input features, 15% of full dataset)\n",
    "    # Y_train (1 label, 70% of full dataset), Y_val (1 label, 15% of full dataset), Y_test (1 label, 15% of full dataset)\n",
    "    X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X, Y, test_size=test_size)\n",
    "    X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)\n",
    "    print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)\n",
    "\n",
    "    # Hyperparameter turning\n",
    "    # values = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "    # for param in values:\n",
    "    #     # model = Sequential([Dense(32, activation='relu', input_shape=(58,)), Dense(32, activation='relu'), Dense(1, activation='sigmoid'),]) # described sequentially, layer-by-layer with 32, 32, and 1 neurons; 58 input features\n",
    "    #     print(\"Param = \" + str(param))\n",
    "        \n",
    "    # SGD Optimizer\n",
    "    param = 1e-2\n",
    "    model = Sequential([Dense(32, activation='relu', input_shape=(58,), kernel_regularizer=l1(param)), Dense(32, activation='relu', kernel_regularizer=l1(param)), Dense(1, activation='sigmoid'),]) # described sequentially, layer-by-layer with 32, 32, and 1 neurons; 58 input features\n",
    "    model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "    history = model.fit(X_train, Y_train, batch_size=32, epochs=100, validation_data=(X_val, Y_val))\n",
    "\n",
    "    # Plot epoch vs. accuracy plot\n",
    "    fig = plt.figure(figsize=(14,10))\n",
    "    plt.plot(history.history['acc'], linewidth=3.5)\n",
    "    plt.plot(history.history['val_acc'], linewidth=3.5)\n",
    "    plt.plot(history.history['loss'], linewidth=3.5)\n",
    "    plt.plot(history.history['val_loss'], linewidth=3.5)\n",
    "    plt.rcParams.update({'font.size': 20})\n",
    "    plt.title('SGD Model Training Loss and Accuracy')\n",
    "    plt.ylabel('Accuracy/Loss', fontsize=20)\n",
    "    plt.xlabel('Epoch', fontsize=20)\n",
    "    plt.ylim(0,4)\n",
    "    plt.legend(['Acc_Train', 'Acc_Val', 'Loss_Train', 'Loss_Val'], loc='upper right')\n",
    "    plt.savefig('SGD.png')\n",
    "    print(\"SGD Accuracy: \" + str(model.evaluate(X_test, Y_test)[1]))\n",
    "\n",
    "    param = 0.5\n",
    "    # Adam optimizer\n",
    "    model_2 = Sequential([Dense(100, activation='relu', input_shape=(58,), kernel_regularizer=l1(param)), Dense(100, activation='relu'), Dense(100, activation='relu'), Dense(100, activation='relu'), Dense(1, activation='sigmoid'),])\n",
    "    model_2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history2 = model_2.fit(X_train, Y_train, batch_size=32, epochs=100, validation_data=(X_val, Y_val))\n",
    "\n",
    "    # Plot epoch vs. accuracy plot\n",
    "    plt.figure()\n",
    "    fig = plt.figure(figsize=(14,10))\n",
    "    plt.plot(history2.history['acc'], linewidth=3.5)\n",
    "    plt.plot(history2.history['val_acc'], linewidth=3.5)\n",
    "    plt.plot(history2.history['loss'], linewidth=3.5)\n",
    "    plt.plot(history2.history['val_loss'], linewidth=3.5)\n",
    "    plt.rcParams.update({'font.size': 20})\n",
    "    # plt.figure(figsize=(14,10))\n",
    "    plt.title('Adam Model Training Loss and Accuracy')\n",
    "    plt.ylabel('Accuracy/Loss', fontsize=20)\n",
    "    plt.xlabel('Epoch', fontsize=20)\n",
    "    plt.ylim(0,4)\n",
    "    plt.legend(['Acc_Train', 'Acc_Val', 'Loss_Train', 'Loss_Val'], loc='upper right')\n",
    "    plt.savefig('Adam.png')\n",
    "    print(\"Adam Accuracy: \" + str(model_2.evaluate(X_test, Y_test)[1]))\n",
    "\n",
    "    print(\"Success!\")\n",
    "\n",
    "def create_model(optimizer='sgd', init='glorot_uniform', loss = 'binary_crossentropy'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='relu', input_shape=(58,), init=init))\n",
    "    model.add(Dense(32, activation='relu', init=init))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def hyperParamTuning(X,y, test_size):\n",
    "    start=time.time()\n",
    "    model = KerasClassifier(build_fn=create_model)\n",
    "    optimizers = ['rmsprop', 'adam', 'sgd']\n",
    "    init = ['glorot_uniform', 'normal', 'uniform']\n",
    "    #'SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam'\n",
    "    loss = ['categorical_crossentropy', 'binary_crossentropy']\n",
    "    # epochs = np.array([50, 100, 150])\n",
    "    epochs = np.array([50])\n",
    "    batches = np.array([5, 10, 20])\n",
    "    param_grid = dict(optimizer=optimizers, nb_epoch=epochs, batch_size=batches, init=init)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "    grid_result = grid.fit(X_train, Y_train)\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    end = time.time()\n",
    "    print(\"Time\", end-start)\n",
    "\n",
    " #     history = model.fit(X_train, Y_train, batch_size=32, epochs=100, validation_data=(X_val, Y_val))\n",
    "\n",
    "    #     # Plot epoch vs. accuracy plot\n",
    "    #     plt.plot(history.history['acc'])\n",
    "    #     plt.plot(history.history['val_acc'])\n",
    "    #     plt.title('Model accuracy')\n",
    "    #     plt.ylabel('Accuracy')\n",
    "    #     plt.xlabel('Epoch')\n",
    "    #     plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    #     plt.show()\n",
    "\n",
    "    #     # Plot epoch vs. loss plot\n",
    "    #     plt.plot(history.history['loss'])\n",
    "    #     plt.plot(history.history['val_loss'])\n",
    "    #     plt.title('Model loss')\n",
    "    #     plt.ylabel('Loss')\n",
    "    #     plt.xlabel('Epoch')\n",
    "    #     plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    #     plt.show()\n",
    "\n",
    "    #     print(\"Accuracy: \" + str(model.evaluate(X_test, Y_test)[1]))\n",
    "    # print(grid_result.grid_scores_)\n",
    "    results = pd.DataFrame.from_dict(grid_result.cv_results_)\n",
    "    print(results)\n",
    "    results.to_csv('results.csv', index=False)\n",
    "    # print(grid_result.cv_results_)\n",
    "\n",
    "    # for params, mean_score, scores in grid_result.cv_results_:\n",
    "    #     print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))\n",
    "    # print(\"total time:\",time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vPwYnJxoQBnO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.92      0.90       154\n",
      "         1.0       0.89      0.83      0.86       117\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       271\n",
      "   macro avg       0.88      0.88      0.88       271\n",
      "weighted avg       0.88      0.88      0.88       271\n",
      "\n",
      "Confusion matrix: \n",
      "[[142  12]\n",
      " [ 20  97]]\n",
      "Accuracy: 0.8819188191881919\n",
      "Precision: 0.8899082568807339\n",
      "Recall: 0.8290598290598291\n",
      "[('discuss_mental_coworkers_Yes', 2.07635515937531), ('leave_Very easy', 2.023382908726718), ('leave_Somewhat easy', 1.7784132016920915), ('self_employed_0', 0.79471236643895), ('leave_Neither easy nor difficult', 0.7508261512223651), ('resources_Yes', 0.7340934894729548), ('leave_Somewhat difficult', 0.704854625858937), ('discuss_mental_coworkers_Maybe', 0.65888791717533), ('size_6-25', 0.6551351254065247), ('size_26-100', 0.6091317236173521), (\"wellness_program_I don't know\", 0.6056404633110037), ('tech_0.0', 0.5948520006481482), ('observe_negative_No', 0.5365107061065039), (\"leave_I don't know\", 0.4676578783045101), ('anon_Yes', 0.4464507108317687), (\"resources_I don't know\", 0.41004419462837166), (\"anon_I don't know\", 0.3213532235216428), ('wellness_program_Yes', 0.2705341646689841), ('observe_negative_Yes, I observed', 0.2219308620848105), ('tech_1.0', 0.19986036579085026), (\"benefits_I don't know\", 0.16589996443561403), ('interview_mental_health_Yes', 0.1636458653404377), ('benefits_Yes', 0.10308714714761526), ('family_history_No', 0.08801608419563897), ('size_1-5', 0.08043852679963584), ('options_No', 0.06816108982162945), ('anon_No', 0.02690843208556697), ('Unnamed: 0', -0.0011055083656069111), ('benefits_No', -0.003750072449149091), (\"observe_negative_I've always been self-employed\", -0.018853539821188984), ('interfere_Unsure', -0.029593522376854982), ('interfere_No', -0.02982660935191105), ('gender_o', -0.035848083787862216), ('wellness_program_No', -0.08146226154100573), ('size_100-500', -0.1326958926798498), ('size_500-1000', -0.14143426425340497), ('interfere_Yes', -0.18517742536415294), ('options_Yes', -0.2114106763308549), ('interview_physical_health_Yes', -0.2165931722201036), ('interview_physical_health_Maybe', -0.21992907223240316), ('family_history_Yes', -0.23533420279925216), ('size_More than 1000', -0.2758628524512819), ('resources_No', -0.34942531766231155), ('interfere_Not applicable to me', -0.353880127719529), ('treatment_1', -0.37953547691439604), ('interview_mental_health_Maybe', -0.3976997721030769), ('observe_negative_Maybe/Not sure', -0.4374197990961559), ('leave_Difficult', -0.5215589354870542), ('gender_m', -0.5625418160464388), ('gender_f', -0.5644119169697248), ('interview_physical_health_No', -0.5827849563897552), ('benefits_Not eligible for coverage / NA', -0.5830796536287958), ('treatment_0', -0.6397717239278669), ('observe_negative_Yes, I experienced', -0.6738976915234907), ('interview_mental_health_No', -0.7852532940796505), (\"family_history_I don't know\", -0.8719890822386704), ('self_employed_1', -1.8140195672812793), ('discuss_mental_coworkers_No', -1.9405307101116613)]\n",
      "Number of features:  58\n",
      "Number of entries:  1351\n",
      "(945, 58) (203, 58) (203, 58) (945, 1) (203, 1) (203, 1)\n",
      "1) LR: Mean = 0.877335 with std = (0.039014)\n",
      "2) LDA: Mean = 0.875185 with std = (0.040162)\n",
      "3) GP: Mean = 0.855073 with std = (0.019240)\n",
      "4) RF: Mean = 0.855006 with std = (0.031191)\n",
      "5) NN: Mean = 0.867839 with std = (0.037726)\n",
      "6) AB: Mean = 0.878387 with std = (0.040935)\n",
      "7) QDA: Mean = 0.707077 with std = (0.046846)\n",
      "8) CART: Mean = 0.829642 with std = (0.028876)\n",
      "9) NB: Mean = 0.688959 with std = (0.038224)\n",
      "10) K_M: Mean = 0.845521 with std = (0.033808)\n",
      "11) K_C: Mean = 0.573684 with std = (0.039729)\n",
      "12) K_E: Mean = 0.845521 with std = (0.033808)\n",
      "13) K_Man: Mean = 0.845521 with std = (0.033808)\n",
      "14) K_Mat: Mean = 0.845521 with std = (0.029559)\n",
      "15) K_J: Mean = 0.846629 with std = (0.035238)\n",
      "16) K_D: Mean = 0.846629 with std = (0.035238)\n",
      "17) K_K: Mean = 0.847682 with std = (0.034929)\n",
      "18) S_Lin: Mean = 0.887861 with std = (0.025849)\n",
      "19) S_RBF: Mean = 0.873068 with std = (0.028140)\n",
      "20) S_Sig: Mean = 0.873068 with std = (0.028140)\n",
      "21) S_Pol: Mean = 0.582083 with std = (0.026955)\n",
      "Index(['principal component 1', 'principal component 2'], dtype='object')\n",
      "58\n",
      "      discuss_mental_supervisor_Yes\n",
      "1260                            1.0\n",
      "1261                            1.0\n",
      "1263                            0.0\n",
      "1264                            0.0\n",
      "1265                            1.0\n",
      "1266                            1.0\n",
      "1267                            1.0\n",
      "1269                            0.0\n",
      "1270                            1.0\n",
      "1271                            0.0\n",
      "1272                            1.0\n",
      "1274                            1.0\n",
      "1278                            0.0\n",
      "1279                            0.0\n",
      "1280                            1.0\n",
      "1281                            1.0\n",
      "1282                            0.0\n",
      "1284                            0.0\n",
      "1286                            0.0\n",
      "1287                            0.0\n",
      "1289                            1.0\n",
      "1291                            1.0\n",
      "1293                            0.0\n",
      "1294                            1.0\n",
      "1295                            0.0\n",
      "1297                            1.0\n",
      "1298                            1.0\n",
      "1299                            1.0\n",
      "1300                            0.0\n",
      "1301                            1.0\n",
      "...                             ...\n",
      "3825                            1.0\n",
      "3827                            0.0\n",
      "3828                            0.0\n",
      "3829                            1.0\n",
      "3830                            0.0\n",
      "3831                            0.0\n",
      "3832                            0.0\n",
      "3833                            0.0\n",
      "3835                            1.0\n",
      "3836                            0.0\n",
      "3837                            0.0\n",
      "3838                            0.0\n",
      "3840                            0.0\n",
      "3842                            0.0\n",
      "3843                            0.0\n",
      "3844                            1.0\n",
      "3846                            0.0\n",
      "3849                            0.0\n",
      "3850                            0.0\n",
      "3851                            1.0\n",
      "3852                            0.0\n",
      "3855                            1.0\n",
      "3856                            0.0\n",
      "3857                            1.0\n",
      "3858                            0.0\n",
      "3859                            1.0\n",
      "3860                            1.0\n",
      "3862                            0.0\n",
      "3864                            1.0\n",
      "3865                            0.0\n",
      "\n",
      "[1351 rows x 1 columns]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.69      0.70       154\n",
      "         1.0       0.60      0.61      0.60       117\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       271\n",
      "   macro avg       0.65      0.65      0.65       271\n",
      "weighted avg       0.66      0.66      0.66       271\n",
      "\n",
      "Confusion matrix: \n",
      "[[107  47]\n",
      " [ 46  71]]\n",
      "Accuracy: 0.6568265682656826\n",
      "Precision: 0.6016949152542372\n",
      "Recall: 0.6068376068376068\n",
      "Index(['principal component 1', 'principal component 2',\n",
      "       'principal component 3'],\n",
      "      dtype='object')\n",
      "58\n",
      "      discuss_mental_supervisor_Yes\n",
      "1260                            1.0\n",
      "1261                            1.0\n",
      "1263                            0.0\n",
      "1264                            0.0\n",
      "1265                            1.0\n",
      "1266                            1.0\n",
      "1267                            1.0\n",
      "1269                            0.0\n",
      "1270                            1.0\n",
      "1271                            0.0\n",
      "1272                            1.0\n",
      "1274                            1.0\n",
      "1278                            0.0\n",
      "1279                            0.0\n",
      "1280                            1.0\n",
      "1281                            1.0\n",
      "1282                            0.0\n",
      "1284                            0.0\n",
      "1286                            0.0\n",
      "1287                            0.0\n",
      "1289                            1.0\n",
      "1291                            1.0\n",
      "1293                            0.0\n",
      "1294                            1.0\n",
      "1295                            0.0\n",
      "1297                            1.0\n",
      "1298                            1.0\n",
      "1299                            1.0\n",
      "1300                            0.0\n",
      "1301                            1.0\n",
      "...                             ...\n",
      "3825                            1.0\n",
      "3827                            0.0\n",
      "3828                            0.0\n",
      "3829                            1.0\n",
      "3830                            0.0\n",
      "3831                            0.0\n",
      "3832                            0.0\n",
      "3833                            0.0\n",
      "3835                            1.0\n",
      "3836                            0.0\n",
      "3837                            0.0\n",
      "3838                            0.0\n",
      "3840                            0.0\n",
      "3842                            0.0\n",
      "3843                            0.0\n",
      "3844                            1.0\n",
      "3846                            0.0\n",
      "3849                            0.0\n",
      "3850                            0.0\n",
      "3851                            1.0\n",
      "3852                            0.0\n",
      "3855                            1.0\n",
      "3856                            0.0\n",
      "3857                            1.0\n",
      "3858                            0.0\n",
      "3859                            1.0\n",
      "3860                            1.0\n",
      "3862                            0.0\n",
      "3864                            1.0\n",
      "3865                            0.0\n",
      "\n",
      "[1351 rows x 1 columns]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.87      0.86       154\n",
      "         1.0       0.82      0.79      0.81       117\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       271\n",
      "   macro avg       0.84      0.83      0.83       271\n",
      "weighted avg       0.84      0.84      0.84       271\n",
      "\n",
      "Confusion matrix: \n",
      "[[134  20]\n",
      " [ 24  93]]\n",
      "Accuracy: 0.8376383763837638\n",
      "Precision: 0.8230088495575221\n",
      "Recall: 0.7948717948717948\n",
      "[0.14071464 0.10664006 0.08144594 0.06195352 0.04740184 0.04063371\n",
      " 0.0377559  0.03618607 0.03269895 0.03050211 0.02843177 0.02694778\n",
      " 0.02642433 0.02466989 0.02231145 0.02210297 0.01990213 0.01947225\n",
      " 0.0188969  0.01651403 0.01498511 0.01410504 0.01321542 0.01222612\n",
      " 0.011874   0.01164663 0.00993873 0.00987149 0.00856768 0.008314\n",
      " 0.00684623 0.00630111 0.00586407 0.00456437 0.00422938 0.00402509\n",
      " 0.00337577]\n",
      "37\n",
      "[0.14071464 0.2473547  0.32880064 0.39075416 0.43815599 0.47878971\n",
      " 0.51654561 0.55273168 0.58543063 0.61593274 0.64436451 0.67131229\n",
      " 0.69773662 0.72240651 0.74471796 0.76682093 0.78672306 0.80619531\n",
      " 0.82509221 0.84160624 0.85659136 0.8706964  0.88391182 0.89613794\n",
      " 0.90801194 0.91965857 0.9295973  0.93946878 0.94803647 0.95635047\n",
      " 0.9631967  0.96949782 0.97536188 0.97992625 0.98415563 0.98818072\n",
      " 0.99155649]\n",
      "(945, 58) (203, 58) (203, 58) (945, 1) (203, 1) (203, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/crystalz/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/crystalz/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 945 samples, validate on 203 samples\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    matplotlib.rcParams.update({'font.size': 10})\n",
    "    who = 'supervisor'\n",
    "    if who != 'supervisor' and who != 'coworkers':\n",
    "        print('Incorrect Inputs')\n",
    "    train, combined = loadData(who)\n",
    "    #weights_supervisor_yes\n",
    "    X,y,feature_cols = buildData(combined, who, train)\n",
    "    logreg = performLogReg(X,y)\n",
    "    weights = printAndShowCoef(feature_cols, logreg)\n",
    "    printListCoefs(X, logreg)\n",
    "    runDifferentModels(X,y)\n",
    "    #     runKNN_SVMModels(X,Y)\n",
    "    testPCA(X, y)\n",
    "    runNeuralNet(X, y, 0.3)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CS 221 Final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
